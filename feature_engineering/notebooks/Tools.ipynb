{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOOLS\n",
    "\n",
    "This notebook contains different sections that help to:\n",
    "- Generate different video variations \n",
    "- Compute metrics using external software like ffmpeg or libav\n",
    "\n",
    "It makes use of different scripts located in the /scripts folder that will help to both generate different renditions from original (1080p) input videos as well as distortions of them (attacks).\n",
    "\n",
    "It also provides means to execute metric extractions from those videos (MS-SSIM, VMAF, SSIM and PSNR) by means of bash shell. These metrics are also utilized in other notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input path configuration\n",
    "\n",
    "The cell below must be executed. It prepares the notebook to point to the local repo structure where the original 1080p renditions are.\n",
    "\n",
    "The expected input structure is:\n",
    "\n",
    "```\n",
    "data\n",
    "├── 1080p\n",
    "│   └── 01.mp4\n",
    "├── 720p\n",
    "│   └── 01.mp4\n",
    "├── 480p\n",
    "│   └── 01.mp4\n",
    "├── 360p\n",
    "│   └── 01.mp4\n",
    "└── 240p\n",
    "|    └── 01.mp4\n",
    "└── 144p\n",
    "    └── 01.mp4    \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "from pathlib import Path\n",
    "\n",
    "current_path = Path(os.path.abspath(''))\n",
    "input_path = (current_path / \"../data/1080p\").resolve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.-Rendition creation\n",
    "## 1.0.- Scaling and bitrate reduction\n",
    "\n",
    "In first place, a dataset with original videos is required. We propose the collection provided in the YT8M notebook available [here](https://github.com/epiclabs-io/YT8M/blob/master/yt8m-crawler.ipynb). Once CSV file with the videos metadata is generated, use [downloader](../../YT8M_downloader/downloader.py) script to download videos. Consider using various format filter values to get e.g. 60 fps videos.\n",
    "\n",
    "## 1.1.- Watermarks\n",
    "\n",
    "There is a python script in order to insert watermarks in the videos. This script receives 4 parameters:\n",
    "- The input path (-i or --input) which is the folder containing 1080p.\n",
    "- The output path (-o or --output) which is the folder where the videos with watermark are going to be stored.\n",
    "- The metadata (-m or --metadata) which is the file containing data about the videos, the most important is the needed bitrate to enconde the video.\n",
    "- The watermark file (-w --watermark) which is the file containing the image to be applied to the video.\n",
    "\n",
    "The output looks like\n",
    "\n",
    "```\n",
    "├── 1080p_watermark\n",
    "│   ├── 01.mp4\n",
    "├── 720p_watermark\n",
    "│   ├── 01.mp4\n",
    "├── 480p_watermark\n",
    "│   ├── 01.mp4\n",
    "├── 360p_watermark\n",
    "│   ├── 01.mp4\n",
    "├── 240p_watermark\n",
    "│   ├── 01.mp4\n",
    "├── 144p_watermark\n",
    "│   ├── 01.mp4\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = (current_path / \"../data\").resolve()\n",
    "metadata_file = (current_path / \"/scripts/yt8m_data.csv\").resolve()\n",
    "watermark_file = (current_path / \"/scripts/watermark/livepeer.png\").resolve()\n",
    "%run -i '/scripts/watermark.py' -i $input_path -o $output_path -m $metadata_file -w $watermark_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2.- Flips / rotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a python script in order to flip / rotate the videos. This script receives 3 parameters:\n",
    "- The input path (-i or --input) which is the folder containing 1080p.\n",
    "- The output path (-o or --output) which is the folder where the flipped videos are going to be stored.\n",
    "- The desired flip or rotation:\n",
    "    -  -vf or --vflip for the vertical flip\n",
    "    -  -hf or --hflip for the horizontal flip\n",
    "    -  -cf or for the 90 degrees clockwise rotation\n",
    "    -  -ccf for the 90 degrees counterclockwise rotation\n",
    "\n",
    "There are implemented the following ways to flip / rotate a video:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3.- Vertical flip\n",
    "\n",
    "The output looks like\n",
    "\n",
    "```\n",
    "├── 1080p_flip_vertical\n",
    "│   ├── 01.mp4\n",
    "├── 720p_flip_vertical\n",
    "│   ├── 01.mp4\n",
    "├── 480p_flip_vertical\n",
    "│   ├── 01.mp4\n",
    "├── 360p_flip_vertical\n",
    "│   ├── 01.mp4\n",
    "├── 240p_flip_vertical\n",
    "│   ├── 01.mp4\n",
    "├── 144p_flip_vertical\n",
    "│   ├── 01.mp4\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = (current_path / \"../data\").resolve()\n",
    "%run -i '/scripts/flip.py' -i $input_path -o $output_path -vf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4.- Horizontal flip\n",
    "\n",
    "The output looks like\n",
    "\n",
    "```\n",
    "├── 1080p_flip_horizontal\n",
    "│   ├── 01.mp4\n",
    "├── 720p_flip_horizontal\n",
    "│   ├── 01.mp4\n",
    "├── 480p_flip_horizontal\n",
    "│   ├── 01.mp4\n",
    "├── 360p_flip_horizontal\n",
    "│   ├── 01.mp4\n",
    "├── 240p_flip_horizontal\n",
    "│   ├── 01.mp4\n",
    "├── 144p_flip_horizontal\n",
    "│   ├── 01.mp4\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = (current_path / \"../data\").resolve()\n",
    "%run -i '/scripts/flip.py' -i $input_path -o $output_path -hf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5.- Rotate 90 degrees clockwise\n",
    "\n",
    "The output looks like\n",
    "\n",
    "```\n",
    "├── 1080p_rotate_90_clockwise\n",
    "│   ├── 01.mp4\n",
    "├── 720p_rotate_90_clockwise\n",
    "│   ├── 01.mp4\n",
    "├── 480p_rotate_90_clockwise\n",
    "│   ├── 01.mp4\n",
    "├── 360p_rotate_90_clockwise\n",
    "│   ├── 01.mp4\n",
    "├── 240p_rotate_90_clockwise\n",
    "│   ├── 01.mp4\n",
    "├── 144p_rotate_90_clockwise\n",
    "│   ├── 01.mp4\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = (current_path / \"../data\").resolve()\n",
    "%run -i '/scripts/flip.py' -i $input_path -o $output_path -cf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6.- Rotate 90 degrees counterclockwise\n",
    "\n",
    "The output looks like\n",
    "\n",
    "```\n",
    "├── 1080p_rotate_90_counterclockwise\n",
    "│   ├── 01.mp4\n",
    "├── 720p_rotate_90_counterclockwise\n",
    "│   ├── 01.mp4\n",
    "├── 480p_rotate_90_counterclockwise\n",
    "│   ├── 01.mp4\n",
    "├── 360p_rotate_90_counterclockwise\n",
    "│   ├── 01.mp4\n",
    "├── 240p_rotate_90_counterclockwise\n",
    "│   ├── 01.mp4\n",
    "├── 144p_rotate_90_counterclockwise\n",
    "│   ├── 01.mp4\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = (current_path / \"../data\").resolve()\n",
    "%run -i '/scripts/flip.py' -i $input_path -o $output_path -ccf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7.- Black and white\n",
    "\n",
    "There is a python script in order to convert color videos to black and white. This script receives 2 parameters:\n",
    "- The input path (-i or --input) which is the folder containing the renditions.\n",
    "- The output path (-o or --output) which is the folder where the black and white videos are going to be stored.\n",
    "\n",
    "The output looks like\n",
    "\n",
    "```\n",
    "├── 1080p_black_and_white\n",
    "│   ├── 01.mp4\n",
    "├── 720p_black_and_white\n",
    "│   ├── 01.mp4\n",
    "├── 480p_black_and_white\n",
    "│   ├── 01.mp4\n",
    "├── 360p_black_and_white\n",
    "│   ├── 01.mp4\n",
    "├── 240p_black_and_white\n",
    "│   ├── 01.mp4\n",
    "├── 144p_black_and_white\n",
    "│   ├── 01.mp4\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = (current_path / \"../data\").resolve()\n",
    "%run -i '/scripts/black_and_white.py' -i $input_path -o $output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.8.- Chroma subsampling\n",
    "\n",
    "There is a python script in order to change the chroma subsampling of the videos. This script receives 4 parameters:\n",
    "- The input path (-i or --input) which is the folder containing the renditions.\n",
    "- The output path (-o or --output) which is the folder where the subsmapled videos are going to be stored.\n",
    "- The metadata (-m or --metadata) which is the file containing data about the videos, the most important is the needed bitrate to enconde the video.\n",
    "- The chosen subsampling (-s --subsampling) which is the chroma subsampling to be applied to the video.\n",
    "\n",
    "The output looks like\n",
    "\n",
    "```\n",
    "├── 720p_chroma_subsampling_chosen_subsampling\n",
    "│   ├── 01.mp4\n",
    "├── 480p_chroma_subsampling_chosen_subsampling\n",
    "│   ├── 01.mp4\n",
    "├── 360p_chroma_subsampling_chosen_subsampling\n",
    "│   ├── 01.mp4\n",
    "├── 240p_chroma_subsampling_chosen_subsampling\n",
    "│   ├── 01.mp4\n",
    "├── 144p_chroma_subsampling_chosen_subsampling\n",
    "│   ├── 01.mp4\n",
    "```\n",
    "\n",
    "Where chosen_subsampling is one of the [ffmpeg valid subsampling](https://trac.ffmpeg.org/wiki/Chroma%20Subsampling), for example: \n",
    "\n",
    "`yuv420p, yuv422p, yuv444p, yuv420p10le, yuv422p10le, yuv444p10le`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = (current_path / \"../data\").resolve()\n",
    "%run -i '/scripts/chroma_subsampling.py' -i $input_path -o $output_path -m $metadata_file -s yuv422p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.9.- low bitrate\n",
    "\n",
    "There is a python script in order to change the bitrate of the videos. This script receives 4 parameters:\n",
    "- The input path (-i or --input) which is the folder containing the renditions.\n",
    "- The output path (-o or --output) which is the folder where the videos with low bitrate are going to be stored.\n",
    "- The metadata (-m or --metadata) which is the file containing data about the videos, the most important is the needed bitrate to enconde the video.\n",
    "- The chosen divisor for the bitrate (-d, --divisor) which is the divisot to be applied to the video bitrate.\n",
    "\n",
    "The output looks like\n",
    "\n",
    "```\n",
    "├── 1080p_low_bitrate_divisor\n",
    "│   ├── 01.mp4\n",
    "├── 720p_low_bitrate_divisor\n",
    "│   ├── 01.mp4\n",
    "├── 480p_low_bitrate_divisor\n",
    "│   ├── 01.mp4\n",
    "├── 360p_low_bitrate_divisor\n",
    "│   ├── 01.mp4\n",
    "├── 240p_low_bitrate_divisor\n",
    "│   ├── 01.mp4\n",
    "├── 144p_low_bitrate_divisor\n",
    "│   ├── 01.mp4\n",
    "```\n",
    "\n",
    "Where divisor is an integer greater than 0 that is going to divide the current bitrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = (current_path / \"../data\").resolve()\n",
    "%run -i '/scripts/low_bitrate.py' -i $input_path -o $output_path -m $metadata_file -d 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.10.- vignette\n",
    "\n",
    "There is a python script in order to apply a vignette filter to the videos. This script receives 3 parameters (One is optional):\n",
    "- The input path (-i or --input) which is the folder containing the renditions.\n",
    "- The output path (-o or --output) which is the folder where the vignetted videos are going to be stored.\n",
    "- The angle (-a or --angle) which is the angle of the vignette filter to be applied to the video. This param is optional and by default is [PI/5](https://ffmpeg.org/ffmpeg-filters.html#vignette-1)\n",
    "\n",
    "The output looks like\n",
    "\n",
    "```\n",
    "├── 1080p_vignette_angle\n",
    "│   ├── 01.mp4\n",
    "├── 720p_vignette_angle\n",
    "│   ├── 01.mp4\n",
    "├── 480p_vignette_angle\n",
    "│   ├── 01.mp4\n",
    "├── 360p_vignette_angle\n",
    "│   ├── 01.mp4\n",
    "├── 240p_vignette_angle\n",
    "│   ├── 01.mp4\n",
    "├── 144p_vignette_angle\n",
    "│   ├── 01.mp4\n",
    "```\n",
    "\n",
    "Where angle is a valid angle for ffmpeg (in the [0,PI/2] range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = (current_path / \"../data\").resolve()\n",
    "%run -i '/scripts/vignette.py' -i $input_path -o $output_path -m $metadata_file -a PI/4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.11.- FPS converter\n",
    "\n",
    "This script converts source videos to common frame rates, and puts results into corresponding folders. It can be applied after all other renditions are created.\n",
    "- The input path (-i or --input) which is the folder containing the renditions.\n",
    "- The output path (-o or --output) which is the folder where the renditions are going to be stored.\n",
    "- GPU flag (-g or --gpu). Whether to use GPU codecs. You need to have Ffmpeg built with Nvidia Codecs for it to work. Default is false.\n",
    "\n",
    "The output folder names will have source-target FPS suffix appended.\n",
    "\n",
    "```\n",
    "├── 1080p_watermark_60-24fps\n",
    "│   ├── <filename>.mp4\n",
    "├── 720p_watermark_60-24fps\n",
    "│   ├── <filename>.mp4\n",
    "├── 480p_watermark_60-24fps\n",
    "│   ├── <filename>.mp4\n",
    "├── 360p_watermark_60-24fps\n",
    "│   ├── <filename>.mp4\n",
    "├── 240p_watermark_60-24fps\n",
    "│   ├── <filename>.mp4\n",
    "├── 144p_watermark_60-24fps\n",
    "│   ├── <filename>.mp4\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "output_path = (current_path / \"../data\").resolve()\n",
    "%run -i '/scripts/fps_converter.py' -i $input_path -o $output_path"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2 Metric extraction\n",
    "\n",
    "In order to extract metrics from the videos above and being able to compare them, a set of scripts are made available below.\n",
    "\n",
    "## 2.1 Compute ms-ssim\n",
    "\n",
    "There is a bash script `evaluate-ms-ssim.sh` in order to calculate the multiscale ssim. This script receives two parameters which are the path where the videos are and the path where the output should be placed. Note that the `../output` folder is the folder where other notebooks are expecting the output.\n",
    "\n",
    "\n",
    "The output structuture is inside the output folder\n",
    "\n",
    "```\n",
    "mssim\n",
    "├── 240\n",
    "│   ├── 01\n",
    "│   │   └── 01_240.log\n",
    "├── 360\n",
    "│   ├── 01\n",
    "│   │   └── 01_360.log\n",
    "├── 480\n",
    "│   ├── 01\n",
    "│   │   └── 01_480.log\n",
    "└── 720\n",
    "    ├── 01\n",
    "        └── 01_720.log \n",
    "```\n",
    "\n",
    "Where the folder indicates the rendition we are using to compare against the original (1080p). \n",
    "A subfolder of this folder contains the name of the asset and finally the file containing the log.\n",
    "\n",
    "The log is a csv file, with the following structure:\n",
    "\n",
    "```\n",
    "ms-ssim, psnr-y, psnr-u, psnr-v\n",
    "0.986889, 32.866684, 43.274622, 42.429359\n",
    "0.985558, 32.394349, 43.344157, 42.658971\n",
    "0.985460, 32.521368, 43.338460, 42.580399\n",
    "0.985896, 32.670122, 43.325404, 42.529248\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shell_path = Path(os.path.abspath(''))\n",
    "shell_input_path = (current_path / \"../data\").resolve()\n",
    "shell_output_path = (current_path / \"../output\").resolve()\n",
    "\n",
    "!bash '/scripts/shell/evaluate-ms-ssim.sh' $shell_input_path $shell_output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.- Compute VMAF\n",
    "\n",
    "There is a bash script `evaluate-vmaf.sh` in order to calculate the vmaf score. This script receives two parameters which are the path where the videos are and the path where the output should be placed. Note that the `../output` folder is the folder where other notebooks are expecting the output.\n",
    "\n",
    "The script will produce the following folder structure:\n",
    "\n",
    "```\n",
    "output/vmaf\n",
    "├── 240\n",
    "│   ├── 01\n",
    "│   │   ├── 01_240.log\n",
    "│   │   └── 01_240.log.out\n",
    "├── 360\n",
    "│   ├── 01\n",
    "│   │   ├── 01_360.log\n",
    "│   │   └── 01_360.log.out\n",
    "├── 480\n",
    "│   ├── 01\n",
    "│   │   ├── 01_480.log\n",
    "│   │   └── 01_480.log.out\n",
    "└── 720\n",
    "    ├── 01\n",
    "        ├── 01_720.log\n",
    "        └── 01_720.log.out\n",
    "```\n",
    "\n",
    "Where the folder indicates the rendition we are using to compare against the original (1080p). \n",
    "A subfolder of this folder contains the name of the asset and finally two files: One containing the result \n",
    "(videoname_rendition_resolution.log) and other containing the output from the ffmpeg (videoname_rendition_resolution.log.out).\n",
    "\n",
    "The log file contains the following information:\n",
    "\n",
    "```\n",
    "Start calculating VMAF score...\n",
    "Exec FPS: 158.922597\n",
    "VMAF score = 90.566873\n",
    "```\n",
    "\n",
    "The interesting line is the third one, containing the vmaf score.\n",
    "\n",
    "The .out file is not worth analyzing as it is the standard ffmpeg output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shell_path = Path(os.path.abspath(''))\n",
    "shell_input_path = (current_path / \"../data\").resolve()\n",
    "shell_output_path = (current_path / \"../output\").resolve()\n",
    "\n",
    "!bash '/scripts/shell/evaluate-vmaf.sh' $shell_input_path $shell_output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3.- Compute ssim and psnr\n",
    "\n",
    "There is a bash script `evaluate-psnr-ssim.sh` in order to calculate the ssim and psnr metrics. This script receives two parameters which are the path where the videos are and the path where the output should be placed. Note that the `../output` folder is the folder where other notebooks are expecting the output.\n",
    "\n",
    "The script will produce the following folder structure:\n",
    "\n",
    "The output structuture is inside the output folder for the psnr\n",
    "\n",
    "```\n",
    "psnr\n",
    "├── 240\n",
    "│   ├── 01\n",
    "│   │   └── 01_240.log\n",
    "├── 360\n",
    "│   ├── 01\n",
    "│   │   └── 01_360.log\n",
    "├── 480\n",
    "│   ├── 01\n",
    "│   │   └── 01_480.log\n",
    "└── 720\n",
    "    ├── 01\n",
    "        └── 01_720.log \n",
    "```\n",
    "\n",
    "Where the folder indicates the rendition we are using to compare against the original (1080p). \n",
    "A subfolder of this folder contains the name of the asset and finally the file containing the log.\n",
    "\n",
    "The log has the following structure:\n",
    "\n",
    "n:1 mse_avg:0.60 mse_y:0.73 mse_u:0.34 mse_v:0.32 psnr_avg:50.37 psnr_y:49.50 psnr_u:52.76 psnr_v:53.01 \n",
    "n:2 mse_avg:0.83 mse_y:1.01 mse_u:0.48 mse_v:0.45 psnr_avg:48.95 psnr_y:48.09 psnr_u:51.29 psnr_v:51.62 \n",
    "n:3 mse_avg:0.77 mse_y:0.94 mse_u:0.45 mse_v:0.44 psnr_avg:49.25 psnr_y:48.42 psnr_u:51.59 psnr_v:51.71 \n",
    "n:4 mse_avg:0.76 mse_y:0.92 mse_u:0.45 mse_v:0.43 psnr_avg:49.32 psnr_y:48.50 psnr_u:51.55 psnr_v:51.76 \n",
    "n:5 mse_avg:0.65 mse_y:0.79 mse_u:0.39 mse_v:0.36 psnr_avg:50.01 psnr_y:49.18 psnr_u:52.22 psnr_v:52.58 \n",
    "\n",
    "\n",
    "The output structuture is inside the output folder for the ssim\n",
    "\n",
    "```\n",
    "ssim\n",
    "├── 240\n",
    "│   ├── 01\n",
    "│   │   └── 01_240.log\n",
    "├── 360\n",
    "│   ├── 01\n",
    "│   │   └── 01_360.log\n",
    "├── 480\n",
    "│   ├── 01\n",
    "│   │   └── 01_480.log\n",
    "└── 720\n",
    "    ├── 01\n",
    "        └── 01_720.log \n",
    "```\n",
    "\n",
    "Where the folder indicates the rendition we are using to compare against the original (1080p). \n",
    "A subfolder of this folder contains the name of the asset and finally the file containing the log.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shell_path = Path(os.path.abspath(''))\n",
    "shell_input_path = (current_path / \"../data\").resolve()\n",
    "shell_output_path = (current_path / \"../output\").resolve()\n",
    "\n",
    "!bash '/scripts/shell/evaluate-psnr-ssim.sh' $shell_input_path $shell_output_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}